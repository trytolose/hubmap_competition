{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "musical-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "critical-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tifffile\n",
    "from torch.utils.data import DataLoader\n",
    "from src.loops.loops import validation_full_image, inference, inference_overlap\n",
    "from src.utils.utils import rle2mask, IMAGE_SIZES, mask2rle\n",
    "from src.transforms.transform import base_transform, valid_transform\n",
    "from src.datasets.dataset import ImageDataset, SingleTiffDataset\n",
    "from src.utils.metrics import dice_numpy\n",
    "import gc\n",
    "from src.datasets.zarr_dataset import ZarrValidDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "visible-fitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 trytolose trytolose 97921014 Mar 25 20:37 ../../submission/fold_0_4096to1024_epoch_49_score_0.9339.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../../submission/fold_0_4096to1024_epoch_49_score_0.9339.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "willing-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTOR = 1\n",
    "CROP_SIZE= 1024 * 4 * FACTOR\n",
    "IMG_TRAIN_SIZE = 1024 * FACTOR\n",
    "BATCH_SIZE = 24\n",
    "NUM_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "central-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/hdd/kaggle/hubmap/input_v2/train.csv\").set_index(\"id\", drop=True)\n",
    "# df_test = pd.read_csv(\"/hdd/kaggle/hubmap/input_v2/test.csv\").set_index(\"id\", drop=True)\n",
    "df_sub = pd.read_csv(\"/hdd/kaggle/hubmap/input_v2/sample_submission.csv\").set_index(\"id\", drop=True)\n",
    "df_crops = pd.read_csv(\"/hdd/kaggle/hubmap/input_v2/train_v1_1024/split_v2.csv\")\n",
    "df_valid = df_crops[df_crops[\"fold\"] == 0].reset_index(drop=True)\n",
    "img_ids = df_valid[\"img_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cognitive-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_imgs = {\n",
    "    0: [\"4ef6695ce\", \"0486052bb\", \"2f6ecfcdf\"],\n",
    "    1: [\"c68fe75ea\", \"095bf7a1f\", \"aaa6a05cc\"],\n",
    "    2: [\"afa5e8098\", \"1e2425f28\", \"b2dc8411c\"],\n",
    "    3: [\"cb2d976f4\", \"8242609fa\", \"54f2eec69\"],\n",
    "    4: [\"26dc41664\", \"b9a3865fc\", \"e79de561c\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "revised-collect",
   "metadata": {},
   "source": [
    "model = smp.Unet(\"resnet34\", encoder_weights=None).cuda()\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"FOLD {fold}\")\n",
    "    w_path = list(Path(f\"../first_launch/fold_{fold}\").glob(\"*pth\"))[0]\n",
    "    model.load_state_dict(torch.load(w_path))\n",
    "    for img_id in fold_imgs[fold]:\n",
    "        rle = df.loc[img_id, 'encoding']\n",
    "        df_img = df_valid[df_valid[\"img_id\"] == img_id].reset_index(drop=True)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        img_ds = SingleTiffDataset(\n",
    "                tiff_path=f\"/hdd/kaggle/hubmap/input_v2/train/{img_id}.tiff\",\n",
    "                transform=valid_transform(CROP_SIZE),\n",
    "                crop_size=CROP_SIZE,\n",
    "                step = 512,\n",
    "        )\n",
    "\n",
    "        img_loader = DataLoader(\n",
    "                dataset=img_ds,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                num_workers=NUM_WORKERS,\n",
    "                pin_memory=True,\n",
    "            )\n",
    "        mask_pred = inference_overlap(img_loader, model, CROP_SIZE).astype(np.float32)\n",
    "        mask_true = rle2mask(rle, (img_loader.dataset.w, img_loader.dataset.h))\n",
    "        dice_full_image = dice_numpy(mask_pred, mask_true)\n",
    "        print(f\"{img_id}: {dice_full_image:.4f}\")\n",
    "        cv2.imwrite(f\"oof_predicts/{img_id}.png\", mask_pred)\n",
    "        del mask_pred, mask_true\n",
    "        gc.collect()\n",
    "        gc.collect()\n",
    "    \n",
    "#     metrics  = validation_full_image(img_loader, model, loss_fn, CROP_SIZE, IMAGE_SIZES[img_id], rle, False)\n",
    "#     dices.append(metrics['dice_full'])\n",
    "    # metrics, mask_pred, mask_true = validation_full_image(img_loader, model, loss_fn, CROP_SIZE, IMAGE_SIZES[img_id], rle, True)\n",
    "#     print(metrics)\n",
    "# print(\"DICE MEAN:\", {np.mean(dices)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuck-failure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 765056\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921016 Mar 31 23:03 1024_256_score_0.9166.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921014 Apr  2 23:46 1024_weighted_epoch_36_score_0.9188.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921015 Mar 31 20:18 512_weighted_08_score_0.9263.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921014 Mar 31 18:06 base_train_weighted_batch_0.8_0.2_e32_score_0.9307.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose      122 Mar 20 23:08 dataset-metadata.json\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921014 Mar 25 17:22 fold_0_2048to512_epoch_48_score_0.9249.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921014 Mar 25 20:37 fold_0_4096to1024_epoch_49_score_0.9339.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921014 Apr  2 14:41 pseudo_score_0.9200.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose       57 Mar 27 21:16 upload.sh\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921013 Mar 31 02:02 zarr_e37_outlier_full_dice_score_0.9444.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../../submission/1024_256_score_0.9166.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "subtle-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.Unet(\"resnet34\", encoder_weights=None).cuda()\n",
    "# w_path = \"../../submission/fold_0_zarr_epoch_23_score_0.9407.pth\"\n",
    "# w_path = \"../../submission/fold_0_old_loader_epoch_38_score_0.9254.pth\"\n",
    "# w_path = \"../../submission/fold_0_zarr_pdf_epoch_34_score_0.9123.pth\"\n",
    "w_path = \"../weights/4096_1028_random_zarr_zarr_4096_1024/0/epoch_35_score_0.9311.pth\"\n",
    "model.load_state_dict(torch.load(w_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fossil-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 478140\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921013 Apr  8 14:17 epoch_27_score_0.9168.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921013 Apr  8 14:18 epoch_28_score_0.9183.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921013 Apr  8 14:25 epoch_33_score_0.9218.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921013 Apr  8 14:26 epoch_34_score_0.9221.pth\n",
      "-rw-rw-r-- 1 trytolose trytolose 97921013 Apr  8 14:28 epoch_35_score_0.9311.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../weights/4096_1028_random_zarr_zarr_4096_1024/0/epoch_35_score_0.9311.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sacred-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ec3f1bb9-anatomical-structure.json  aa05346ff-anatomical-structure.json\n",
      "2ec3f1bb9.tiff\t\t\t     aa05346ff.tiff\n",
      "3589adb90-anatomical-structure.json  d488c759a-anatomical-structure.json\n",
      "3589adb90.tiff\t\t\t     d488c759a.tiff\n",
      "57512b7f1-anatomical-structure.json  sample_submission.csv\n",
      "57512b7f1.tiff\n"
     ]
    }
   ],
   "source": [
    "!ls /hdd/kaggle/hubmap/input_v2/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "controversial-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                           | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 6/6 [01:20<00:00, 13.39s/it]\n",
      "  0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ef6695ce: 0.9363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 3/3 [00:31<00:00, 10.55s/it]\n",
      "  0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0486052bb: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 3/3 [00:27<00:00,  9.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f6ecfcdf: 0.9518\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "print(f\"FOLD {fold}\")\n",
    "for img_id in fold_imgs[fold]:\n",
    "    rle = df.loc[img_id, 'encoding']\n",
    "    df_img = df_valid[df_valid[\"img_id\"] == img_id].reset_index(drop=True)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    img_ds = SingleTiffDataset(\n",
    "            tiff_path=f\"/hdd/kaggle/hubmap/input_v2/train/{img_id}.tiff\",\n",
    "            transform=valid_transform(IMG_TRAIN_SIZE),\n",
    "            crop_size=CROP_SIZE,\n",
    "            step = CROP_SIZE,\n",
    "    )\n",
    "\n",
    "    img_loader = DataLoader(\n",
    "            dataset=img_ds,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    mask_pred = inference(img_loader, model, CROP_SIZE, IMG_TRAIN_SIZE).astype(np.float32)\n",
    "#     input_path = \"../../input/zarr_train\"\n",
    "#     val_ds = ZarrValidDataset(\n",
    "#         img_id,\n",
    "#         img_path=input_path,\n",
    "#         transform=valid_transform(IMG_TRAIN_SIZE),\n",
    "#         crop_size=IMG_TRAIN_SIZE,\n",
    "#         step=IMG_TRAIN_SIZE,\n",
    "#     )\n",
    "\n",
    "#     img_loader = DataLoader(\n",
    "#         dataset=val_ds,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         shuffle=False,\n",
    "#         num_workers=10,\n",
    "#         pin_memory=True,\n",
    "#     )\n",
    "\n",
    "#     metrics_val, mask_pred = validation_full_image(\n",
    "#         img_loader, model, torch.nn.BCEWithLogitsLoss(), rle=rle, return_mask=True,\n",
    "#     )\n",
    "#     print(f\"dice_pos: {metrics_val['dice_pos'].4f}, dice_neg: {metrics_val['dice_neg']:.4f}\")\n",
    "\n",
    "    mask_true = rle2mask(rle, (img_loader.dataset.w, img_loader.dataset.h))\n",
    "    dice_full_image = dice_numpy(mask_pred, mask_true)\n",
    "    print(f\"{img_id}: {dice_full_image:.4f}\")\n",
    "#     cv2.imwrite(f\"oof_predicts/{img_id}.png\", mask_pred)\n",
    "#     break\n",
    "    del mask_pred, mask_true\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-kitty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "difficult-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred = (mask_pred>0.5).astype(np.uint8)\n",
    "rle_pred = mask2rle(mask_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enclosed-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"img_id\": \"57512b7f1\", \"encoding\": rle_pred}, index=[0], columns=['img_id', 'encoding']).to_csv(\"no_resize_pred.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "leading-translation",
   "metadata": {},
   "source": [
    "../weights/zarr_full_image_val/fold_0/fold_0_avg_0.9463.pth\n",
    "              x1    x2     x4\n",
    "4ef6695ce: 0.9396 0.9404 0.9411\n",
    "0486052bb: 0.9496 0.9511 0.9504\n",
    "2f6ecfcdf: 0.9497 0.9531 0.9520"
   ]
  },
  {
   "cell_type": "raw",
   "id": "apparent-packet",
   "metadata": {},
   "source": [
    "../weights/zarr_full_image_val/fold_0/epoch_28_score_0.9450.pth\n",
    "              x1    x4\n",
    "4ef6695ce: 0.9370 0.9396\n",
    "0486052bb: 0.9489 0.9509\n",
    "2f6ecfcdf: 0.9491 0.9507"
   ]
  },
  {
   "cell_type": "raw",
   "id": "impressive-relevance",
   "metadata": {},
   "source": [
    "../weights/zarr_full_image_val/fold_0/epoch_38_score_0.9461.pth\n",
    "#zarr new    x1     x4\n",
    "4ef6695ce: 0.9411 0.9425\n",
    "0486052bb: 0.9473 0.9511\n",
    "2f6ecfcdf: 0.9499 0.9509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sacred-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9422333333333333\n",
      "0.9422333333333333\n",
      "0.9439333333333333\n"
     ]
    }
   ],
   "source": [
    "print((0.9398+0.9395+0.9474)/3) #base\n",
    "print((0.9352+0.9421+0.9494)/3) #zarr dl\n",
    "print((0.9404+0.9394+0.9520)/3) #avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "complimentary-township",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9422333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.9352, 0.9421, 0.9494])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "waiting-world",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9422333333333333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.9398, 0.9395, 0.9474])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "intense-cycle",
   "metadata": {},
   "source": [
    "            1024   1024-overlap   2048->512   4096->1024       (4096->1024)x4   (4096->1024)x2  (4096->1024)x6\n",
    "4ef6695ce: 0.9350    0.9384        0.9359      0.9398              0.9418          0.9413         0.9418\n",
    "0486052bb: 0.9406    0.9463        0.9299      0.9395              0.9446          0.9405         0.9438\n",
    "2f6ecfcdf: 0.9485    0.9515        0.9466      0.9474              0.9520          0.9551         0.9508\n",
    "    \n",
    "c68fe75ea: 0.7840    0.7886\n",
    "095bf7a1f: 0.9340    0.9351\n",
    "aaa6a05cc: 0.9115    0.9229\n",
    "    \n",
    "afa5e8098: 0.8858    0.8936\n",
    "1e2425f28: 0.9330    0.9355\n",
    "b2dc8411c: 0.9475    0.9475\n",
    "\n",
    "cb2d976f4: 0.9418    0.9447\n",
    "8242609fa: 0.9527    0.9536\n",
    "54f2eec69: 0.9243    0.9273\n",
    "\n",
    "26dc41664: 0.9405    0.9427\n",
    "b9a3865fc: 0.9433    0.9448\n",
    "e79de561c: 0.9241    0.9287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "green-michael",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 107668\n",
      "-rw-rw-r-- 1 trytolose trytolose 14233992 Mar 22 11:37 1.0-eda.ipynb\n",
      "-rw-rw-r-- 1 trytolose trytolose    22354 Mar 23 19:50 2.0-train_split.ipynb\n",
      "-rw-rw-r-- 1 trytolose trytolose  1963004 Mar 19 16:06 256x256-images.ipynb\n",
      "-rw-rw-r-- 1 trytolose trytolose 18634436 Mar 23 20:00 3.0-inference.ipynb\n",
      "-rw-rw-r-- 1 trytolose trytolose 70047264 Mar 23 19:48 bayanof.zip\n",
      "drwxrwxr-x 2 trytolose trytolose     4096 Mar 23 13:48 oof_predicts\n",
      "-rw-rw-r-- 1 trytolose trytolose    92472 Mar 21 14:17 pred_mask_3.png\n",
      "drwxrwxr-x 3 trytolose trytolose     4096 Mar 23 19:49 rinat\n",
      "-rw-rw-r-- 1 trytolose trytolose  5228237 Mar 21 17:18 submission.csv\n",
      "drwxrwxr-x 2 trytolose trytolose     4096 Mar 20 18:37 test\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-hebrew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "encouraging-amendment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trytolose/miniconda3/envs/audio/lib/python3.8/site-packages/rasterio/__init__.py:207: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "100%|███████████████████████████████████| 3/3 [02:05<00:00, 41.72s/it]\n",
      "100%|███████████████████████████████████| 2/2 [01:15<00:00, 37.97s/it]\n",
      "100%|███████████████████████████████████| 4/4 [02:29<00:00, 37.44s/it]\n",
      "100%|███████████████████████████████████| 4/4 [02:37<00:00, 39.45s/it]\n",
      "100%|███████████████████████████████████| 5/5 [02:27<00:00, 29.53s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for img_id in df_sub.index:\n",
    "    img_ds = SingleTiffDataset(\n",
    "            tiff_path=f\"/hdd/kaggle/hubmap/input_v2/test/{img_id}.tiff\",\n",
    "            transform=valid_transform(IMG_TRAIN_SIZE),\n",
    "            crop_size=CROP_SIZE,\n",
    "            step = CROP_SIZE,\n",
    "    )\n",
    "\n",
    "    img_loader = DataLoader(\n",
    "            dataset=img_ds,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    mask_pred = inference(img_loader, model, CROP_SIZE, IMG_TRAIN_SIZE).astype(np.float32)\n",
    "    mask_pred = (mask_pred > 0.5).astype(np.uint8)\n",
    "    mask_rle = mask2rle(mask_pred)\n",
    "    df_sub.loc[img_id, \"predicted\"] = mask_rle\n",
    "#     break\n",
    "    del mask_pred\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "first-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"1024_resize.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "informed-advancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2ec3f1bb9</th>\n",
       "      <td>60762295 15 60786278 34 60810260 47 60834241 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589adb90</th>\n",
       "      <td>68658992 23 68688384 70 68717813 77 68747243 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d488c759a</th>\n",
       "      <td>191139775 58 191186435 58 191233095 58 1912797...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa05346ff</th>\n",
       "      <td>52856702 6 52887407 36 52918120 49 52948833 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57512b7f1</th>\n",
       "      <td>271347246 6 271380483 13 271413720 20 27144695...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   predicted\n",
       "id                                                          \n",
       "2ec3f1bb9  60762295 15 60786278 34 60810260 47 60834241 6...\n",
       "3589adb90  68658992 23 68688384 70 68717813 77 68747243 8...\n",
       "d488c759a  191139775 58 191186435 58 191233095 58 1912797...\n",
       "aa05346ff  52856702 6 52887407 36 52918120 49 52948833 61...\n",
       "57512b7f1  271347246 6 271380483 13 271413720 20 27144695..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "discrete-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "z = zarr.zeros((10000, 10000), chunks=(1000, 1000), dtype='i1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "central-manhattan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array (10000, 10000) int8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-venezuela",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
