{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demographic-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advanced-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "from torch.utils.data import DataLoader\n",
    "from src.loops.loops import validation_full_image, inference, inference_overlap\n",
    "from src.utils.utils import rle2mask, IMAGE_SIZES, mask2rle\n",
    "from src.transforms.transform import base_transform, valid_transform\n",
    "from src.datasets.dataset import ImageDataset, SingleTiffDataset\n",
    "from src.utils.metrics import dice_numpy\n",
    "import gc\n",
    "import rasterio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "detailed-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/hdd/kaggle/hubmap/input_v2/train.csv\").set_index(\"id\", drop=True)\n",
    "df_sub = pd.read_csv(\"/hdd/kaggle/hubmap/input_v2/sample_submission.csv\").set_index(\"id\", drop=True)\n",
    "df_crops = pd.read_csv(\"/hdd/kaggle/hubmap/input_v2/train_v1_1024/split_v2.csv\")\n",
    "df_valid = df_crops[df_crops[\"fold\"] == 0].reset_index(drop=True)\n",
    "img_ids = df_valid[\"img_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interested-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(img, mask, color=(0, 0, 255), thinkness=10):\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "#     print(len(contours))\n",
    "#     print(type(img), img.dtype)\n",
    "    for i in range(0, len(contours)):\n",
    "#         print(i)\n",
    "        cv2.polylines(img, np.int32(contours[i]), True, color, thinkness)\n",
    "\n",
    "    \n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collective-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_id = \"57512b7f1\"\n",
    "def get_tiff(img_id, path=\"/hdd/kaggle/hubmap/input_v2/test\"):\n",
    "    img_path = Path(path) / f\"{img_id}.tiff\"\n",
    "    dataset = rasterio.open(img_path, num_threads=\"all_cpus\")\n",
    "    # mask_main, mask_second = create_masks(img_id, rle, path)\n",
    "\n",
    "    h, w = dataset.height, dataset.width\n",
    "    if dataset.count == 3:\n",
    "        image = dataset.read()#.transpose(1, 2, 0).astype(np.uint8)\n",
    "        image = np.stack([x for x in image], axis=2).astype(np.uint8)\n",
    "    else:\n",
    "        layers = []\n",
    "        subdatasets = dataset.subdatasets\n",
    "        if len(subdatasets) > 0:\n",
    "            for i, subdataset in enumerate(subdatasets, 0):\n",
    "                layers.append(rasterio.open(subdataset))\n",
    "        image = np.stack([x.read().squeeze() for x in layers], axis=2).astype(np.uint8)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "innovative-petite",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fdf50ae2f397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_public\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_pred_no_resize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1024_no_resize.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_pred_resize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1024_resize.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_public\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/audio/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/audio/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/audio/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/audio/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/audio/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/audio/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \"\"\"\n\u001b[0;32m-> 1357\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/audio/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'submission.csv'"
     ]
    }
   ],
   "source": [
    "df_public = pd.read_csv(\"submission.csv\").set_index(\"id\", drop=True)\n",
    "df_pred_no_resize = pd.read_csv(\"1024_no_resize.csv\").set_index('id')\n",
    "df_pred_resize = pd.read_csv(\"1024_resize.csv\").set_index(\"id\", drop=True)\n",
    "\n",
    "for img_id in df_public.index[1:]:\n",
    "#     print(img_id)\n",
    "    image = get_tiff(img_id)\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    mask_no_resize = rle2mask(df_pred_no_resize.loc[img_id, \"predicted\"], (w, h))\n",
    "    mask_public = rle2mask(df_public.loc[img_id, \"predicted\"], (w, h))\n",
    "    mask_resize = rle2mask(df_pred_resize.loc[img_id, \"predicted\"], (w, h))\n",
    "\n",
    "    draw_contours(image, mask_public, (0, 255, 0), thinkness=17)\n",
    "    draw_contours(image, mask_resize, (255, 0, 0), thinkness=14)\n",
    "    draw_contours(image, mask_no_resize, (0, 0, 255), thinkness=10)\n",
    "    cv2.imwrite(f\"/hdd/kaggle/hubmap/public_predicted/{img_id}.tiff\", image)\n",
    "    \n",
    "    del image, mask_no_resize, mask_public, mask_resize\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-vegetable",
   "metadata": {},
   "source": [
    "## Draw contours on train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spatial-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f6ecfcdf\n",
      "<class 'numpy.ndarray'> uint8\n",
      "8242609fa\n",
      "<class 'numpy.ndarray'> uint8\n",
      "aaa6a05cc\n",
      "<class 'numpy.ndarray'> uint8\n",
      "cb2d976f4\n",
      "<class 'numpy.ndarray'> uint8\n",
      "b9a3865fc\n",
      "<class 'numpy.ndarray'> uint8\n",
      "b2dc8411c\n",
      "<class 'numpy.ndarray'> uint8\n",
      "0486052bb\n",
      "<class 'numpy.ndarray'> uint8\n",
      "e79de561c\n",
      "<class 'numpy.ndarray'> uint8\n",
      "095bf7a1f\n",
      "<class 'numpy.ndarray'> uint8\n",
      "54f2eec69\n",
      "<class 'numpy.ndarray'> uint8\n",
      "4ef6695ce\n",
      "<class 'numpy.ndarray'> uint8\n",
      "26dc41664\n",
      "<class 'numpy.ndarray'> uint8\n",
      "c68fe75ea\n",
      "<class 'numpy.ndarray'> uint8\n",
      "afa5e8098\n",
      "<class 'numpy.ndarray'> uint8\n",
      "1e2425f28\n",
      "<class 'numpy.ndarray'> uint8\n"
     ]
    }
   ],
   "source": [
    "for img_id in df.index:\n",
    "    print(img_id)\n",
    "    image = get_tiff(img_id, path=\"/hdd/kaggle/hubmap/input_v2/train\")\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    mask_gt = rle2mask(df.loc[img_id, \"encoding\"], (w, h))\n",
    "    draw_contours(image, mask_gt, (0, 0, 255), thinkness=10)\n",
    "    cv2.imwrite(f\"/hdd/kaggle/hubmap/train_with_mask/{img_id}.tiff\", image)\n",
    "    \n",
    "    del image, mask_gt\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "outer-poetry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0486052bb.tiff\t26dc41664.tiff\t54f2eec69.tiff\tafa5e8098.tiff\tc68fe75ea.tiff\n",
      "095bf7a1f.tiff\t2f6ecfcdf.tiff\t8242609fa.tiff\tb2dc8411c.tiff\tcb2d976f4.tiff\n",
      "1e2425f28.tiff\t4ef6695ce.tiff\taaa6a05cc.tiff\tb9a3865fc.tiff\te79de561c.tiff\n"
     ]
    }
   ],
   "source": [
    "!ls /hdd/kaggle/hubmap/train_with_mask/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sonic-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 66672\n",
      "-rw-rw-r-- 1 trytolose trytolose 6411831 Apr 11 11:18 1024_256_score_0.9166_lb_0.923.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose 5915930 Apr 26 13:09 1024_512_2_head_897lb.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose 5403366 Apr 23 21:55 2048_1024_b3.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose 6372875 Apr 12 11:17 924lb.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose     141 Apr 14 13:00 dataset-metadata.json\n",
      "-rw-rw-r-- 1 trytolose trytolose 6961344 Apr 11 21:51 effnet-0.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose 6378633 Apr 11 22:20 effnet-1.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose 6256218 Apr 11 19:44 hard_augs.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose 5586532 Apr 12 23:25 no_resize_1024_lb_920.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose 6314221 Apr 11 13:49 public_aug_w0.5_epoch_34_score_0.9175_lb_0.921.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose 6355181 Apr 11 11:19 public_aug_w0.5_myloss_epoch_34_score_0.9175_lb_0.918.csv\n",
      "-rw-rw-r-- 1 trytolose trytolose 6288705 Apr 11 20:01 random_4096_1024_lb_921.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l public_predicts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "atmospheric-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/home/trytolose/miniconda3/envs/audio/lib/python3.8/site-packages/rasterio/__init__.py:207: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "100%|██████████| 5/5 [05:27<00:00, 65.50s/it]\n"
     ]
    }
   ],
   "source": [
    "df_pred_923 = pd.read_csv(\"public_predicts/924lb.csv\").set_index('id')\n",
    "df_pred_aug = pd.read_csv(\"public_predicts/1024_512_2_head_897lb.csv\").set_index('id')\n",
    "\n",
    "\n",
    "for img_id in tqdm(df_pred_923.index):\n",
    "#     print(img_id)\n",
    "    image = get_tiff(img_id)\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    mask_923 = rle2mask(df_pred_923.loc[img_id, \"predicted\"], (w, h))\n",
    "    mask_aug = rle2mask(df_pred_aug.loc[img_id, \"predicted\"], (w, h))\n",
    "\n",
    "    draw_contours(image, mask_923, (0, 255, 0), thinkness=10)\n",
    "    draw_contours(image, mask_aug, (255, 0, 0), thinkness=8)\n",
    "    cv2.imwrite(f\"/hdd/kaggle/hubmap/public_924_and_2048_b3/{img_id}.tiff\", image)\n",
    "    \n",
    "    del image, mask_923, mask_aug\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "possible-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /hdd/kaggle/hubmap/public_924_and_2048_b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accepted-columbus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "drwxrwxr-x 5 trytolose trytolose 4096 Nov 22 16:56 input\n",
      "drwxrwxr-x 7 trytolose trytolose 4096 Mar 25 19:39 input_v2\n",
      "drwxrwxr-x 2 trytolose trytolose 4096 Apr  3 21:02 public_predicted\n",
      "drwxrwxr-x 2 trytolose trytolose 4096 Apr  5 12:29 train_with_mask\n"
     ]
    }
   ],
   "source": [
    "!ls /hdd/kaggle/hubmap/ -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "varying-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /hdd/kaggle/hubmap/public_923_4096 /hdd/kaggle/hubmap/public_923_effnet_0 /hdd/kaggle/hubmap/public_predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "conceptual-vitamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc_coords\t       train_1024_256_pseudo_v1  zarr_pdf\n",
      "d48_hand_labelled.csv  train_1024_512\t\t zarr_train\n",
      "train_1024_256\t       train_v3_4096_1024\t zarr_train_orig\n"
     ]
    }
   ],
   "source": [
    "!ls ../../input/d48_hand_labelled.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assumed-explanation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2ec3f1bb9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589adb90</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d488c759a</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa05346ff</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57512b7f1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           predicted\n",
       "id                  \n",
       "2ec3f1bb9        NaN\n",
       "3589adb90        NaN\n",
       "d488c759a        NaN\n",
       "aa05346ff        NaN\n",
       "57512b7f1        NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "patent-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/home/trytolose/miniconda3/envs/audio/lib/python3.8/site-packages/rasterio/__init__.py:207: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "100%|██████████| 5/5 [06:06<00:00, 73.32s/it]\n"
     ]
    }
   ],
   "source": [
    "df_pred_923 = pd.read_csv(\"public_predicts/v5_r34.csv\").set_index('id')\n",
    "df_pred_aug = pd.read_csv(\"public_predicts/v5_r34_v2.csv\").set_index('id')\n",
    "\n",
    "\n",
    "for img_id in tqdm(df_sub.index):\n",
    "#     print(img_id)\n",
    "    image = get_tiff(img_id)\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    mask_923 = rle2mask(df_pred_923.loc[img_id, \"predicted\"], (w, h))\n",
    "    mask_aug = rle2mask(df_pred_aug.loc[img_id, \"predicted\"], (w, h))\n",
    "\n",
    "    draw_contours(image, mask_923, (0, 255, 0), thinkness=10)\n",
    "    draw_contours(image, mask_aug, (255, 0, 0), thinkness=8)\n",
    "    cv2.imwrite(f\"/hdd/kaggle/hubmap/vitaly_timur/{img_id}.tiff\", image)\n",
    "    \n",
    "    del image, mask_923, mask_aug\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integrated-joshua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory '/hdd/kaggle/hubmap/vitaly_timur/': File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /hdd/kaggle/hubmap/vitaly_timur/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "broke-fetish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 260\n",
      "drwxrwxr-x 2 trytolose trytolose 126976 May  7 13:58 images_1024\n",
      "drwxrwxr-x 2 trytolose trytolose   4096 May  7 14:07 labeled\n",
      "drwxrwxr-x 2 trytolose trytolose 126976 May  7 13:58 masks_1024\n"
     ]
    }
   ],
   "source": [
    "!mkdir /hdd/kaggle/hubmap/input_v2/external/labeled\n",
    "!ls -l /hdd/kaggle/hubmap/input_v2/external/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broke-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = Path(\"/hdd/kaggle/hubmap/input_v2/external/images_1024\").glob(\"*.png\")\n",
    "masks_paths = Path(\"/hdd/kaggle/hubmap/input_v2/external/masks_1024\").glob(\"*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "furnished-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = list(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "accessible-likelihood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2574/2574 [05:42<00:00,  7.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_path in tqdm(img_paths):\n",
    "    im_path = str(img_path)\n",
    "    mk_path = im_path.replace(\"images_1024\", \"masks_1024\")\n",
    "    img = cv2.imread(im_path, -1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    mask = cv2.imread(mk_path, -0)\n",
    "    \n",
    "    draw_contours(img, mask, (0, 255, 0), thinkness=3)\n",
    "    cv2.imwrite(f\"/hdd/kaggle/hubmap/input_v2/external/labeled/{img_path.name}\", img)\n",
    "    \n",
    "#     plt.figure(figsize=(7,7))\n",
    "#     plt.imshow(img)\n",
    "#     plt.imshow(mask, alpha=0.3)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-speech",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
